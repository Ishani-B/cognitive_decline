{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7a0e71-0492-43d3-a8c0-f9107630de0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking data directory: output_lexical_metrics\n",
      " - Subfolder 'output_lexical_metrics/cc': FOUND\n",
      " - Subfolder 'output_lexical_metrics/cd': FOUND\n",
      "\n",
      "Loading CSV files...\n",
      " * 54 files in 'cc'\n",
      " * 54 files in 'cd'\n",
      "\n",
      "Total samples: 108 (cc=54, cd=54)\n",
      "\n",
      "Missing values per feature:\n",
      "all_freq_raw_mean                 1\n",
      "all_freq_log_mean                 1\n",
      "all_cd_raw_mean                   1\n",
      "all_cd_log_mean                   1\n",
      "all_concreteness_m_mean           1\n",
      "all_concreteness_sd_mean          1\n",
      "all_mean_cos_mean                 1\n",
      "all_SemD_mean                     1\n",
      "all_BNC_wordcount_mean            1\n",
      "all_BNC_contexts_mean             1\n",
      "all_BNC_freq_mean                 1\n",
      "all_lg_BNC_freq_mean              1\n",
      "all_phonemes_mean                 1\n",
      "content_freq_raw_mean             1\n",
      "content_freq_log_mean             1\n",
      "content_cd_raw_mean               1\n",
      "content_cd_log_mean               1\n",
      "content_concreteness_m_mean       1\n",
      "content_concreteness_sd_mean      1\n",
      "content_mean_cos_mean             1\n",
      "content_SemD_mean                 1\n",
      "content_BNC_wordcount_mean        1\n",
      "content_BNC_contexts_mean         1\n",
      "content_BNC_freq_mean             1\n",
      "content_lg_BNC_freq_mean          1\n",
      "content_phonemes_mean             1\n",
      "noun_freq_raw_mean                1\n",
      "noun_freq_log_mean                1\n",
      "noun_cd_raw_mean                  1\n",
      "noun_cd_log_mean                  1\n",
      "noun_concreteness_m_mean          2\n",
      "noun_concreteness_sd_mean         2\n",
      "noun_mean_cos_mean                1\n",
      "noun_SemD_mean                    1\n",
      "noun_BNC_wordcount_mean           1\n",
      "noun_BNC_contexts_mean            1\n",
      "noun_BNC_freq_mean                1\n",
      "noun_lg_BNC_freq_mean             1\n",
      "noun_phonemes_mean                1\n",
      "POS_DET_per100                    1\n",
      "POS_NOUN_per100                   1\n",
      "POS_CCONJ_per100                 11\n",
      "POS_VERB_per100                   1\n",
      "POS_PRON_per100                   1\n",
      "POS_ADP_per100                    1\n",
      "POS_PROPN_per100                 73\n",
      "POS_INTJ_per100                  17\n",
      "POS_AUX_per100                    8\n",
      "POS_ADJ_per100                   10\n",
      "POS_SCONJ_per100                 45\n",
      "POS_PART_per100                  23\n",
      "POS_ADV_per100                    6\n",
      "POS_NUM_per100                   73\n",
      "POS_X_per100                    104\n",
      "POS_PUNCT_per100                107\n",
      "dtype: int64\n",
      "\n",
      "Imputing missing values using column means...\n",
      "Imputation complete. Any missing now: True\n",
      "\n",
      "Splitting data (80% train, 20% test)...\n",
      " Training samples: 86\n",
      " Test samples:     22\n",
      "\n",
      "Initializing RandomForestClassifier...\n",
      "Starting model training...\n",
      "Training finished.\n",
      "\n",
      "Evaluating on test set...\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.82      0.72        11\n",
      "           1       0.75      0.55      0.63        11\n",
      "\n",
      "    accuracy                           0.68        22\n",
      "   macro avg       0.70      0.68      0.68        22\n",
      "weighted avg       0.70      0.68      0.68        22\n",
      "\n",
      "Confusion Matrix:\n",
      " [[9 2]\n",
      " [5 6]]\n",
      "\n",
      "Top 10 feature importances:\n",
      "all_BNC_wordcount_mean         0.062959\n",
      "POS_NOUN_per100                0.055712\n",
      "all_BNC_freq_mean              0.040771\n",
      "content_freq_log_mean          0.039991\n",
      "content_concreteness_m_mean    0.037332\n",
      "all_freq_log_mean              0.035821\n",
      "content_cd_log_mean            0.035291\n",
      "content_phonemes_mean          0.033015\n",
      "content_freq_raw_mean          0.029666\n",
      "content_cd_raw_mean            0.028452\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# 1. Configure your data directory\n",
    "base_dir = 'output_lexical_metrics'\n",
    "\n",
    "# 2. Verify directory structure\n",
    "print(f\"Checking data directory: {base_dir}\")\n",
    "if not os.path.isdir(base_dir):\n",
    "    raise FileNotFoundError(f\"Data directory '{base_dir}' does not exist.\")\n",
    "for subgroup in ['cc', 'cd']:\n",
    "    subgroup_path = os.path.join(base_dir, subgroup)\n",
    "    print(f\" - Subfolder '{subgroup_path}': {'FOUND' if os.path.isdir(subgroup_path) else 'MISSING'}\")\n",
    "    if not os.path.isdir(subgroup_path):\n",
    "        raise FileNotFoundError(f\"Expected subfolder '{subgroup_path}' not found.\")\n",
    "\n",
    "# 3. Load CSV metrics and labels\n",
    "print(\"\\nLoading CSV files...\")\n",
    "data_rows, labels = [], []\n",
    "for label in ['cc', 'cd']:\n",
    "    folder = os.path.join(base_dir, label)\n",
    "    files = [f for f in os.listdir(folder) if f.lower().endswith('.csv')]\n",
    "    print(f\" * {len(files)} files in '{label}'\")\n",
    "    for fname in files:\n",
    "        df = pd.read_csv(os.path.join(folder, fname))\n",
    "        data_rows.append(df.iloc[0])\n",
    "        labels.append(label)\n",
    "\n",
    "# 4. Build DataFrame\n",
    "df = pd.DataFrame(data_rows)\n",
    "df['label'] = labels\n",
    "print(f\"\\nTotal samples: {len(df)} (cc={df.label.value_counts()['cc']}, cd={df.label.value_counts()['cd']})\")\n",
    "\n",
    "# 5. Separate features/target and check for NaNs\n",
    "X = df.drop(columns=['label'])\n",
    "y = df['label'].map({'cc': 0, 'cd': 1})\n",
    "\n",
    "print(\"\\nMissing values per feature:\")\n",
    "missing = X.isnull().sum()\n",
    "print(missing[missing > 0] if missing.any() else \"No missing values!\")\n",
    "\n",
    "# 6. Impute missing values with mean\n",
    "if missing.any():\n",
    "    print(\"\\nImputing missing values using column means...\")\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    X = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n",
    "    print(\"Imputation complete. Any missing now:\", X.isnull().sum().sum() == 0)\n",
    "\n",
    "# 7. Train/test split\n",
    "print(\"\\nSplitting data (80% train, 20% test)...\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "print(f\" Training samples: {X_train.shape[0]}\")\n",
    "print(f\" Test samples:     {X_test.shape[0]}\")\n",
    "\n",
    "# 8. Initialize and train Random Forest\n",
    "print(\"\\nInitializing RandomForestClassifier...\")\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=None,\n",
    "    min_samples_split=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"Starting model training...\")\n",
    "rf.fit(X_train, y_train)\n",
    "print(\"Training finished.\")\n",
    "\n",
    "# 9. Evaluate\n",
    "print(\"\\nEvaluating on test set...\")\n",
    "y_pred = rf.predict(X_test)\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# 10. Feature importances (top 10)\n",
    "importances = pd.Series(rf.feature_importances_, index=X.columns)\n",
    "top_features = importances.sort_values(ascending=False).head(10)\n",
    "print(\"\\nTop 10 feature importances:\")\n",
    "print(top_features)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
